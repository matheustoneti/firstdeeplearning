{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMM+II4HeHGkWuKfrlk5dk3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matheustoneti/firstdeeplearning/blob/main/My_first_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiGMrkIknzy7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados = pd.read_csv('water_potability.csv')"
      ],
      "metadata": {
        "id": "LwFOoGokpObr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados.fillna(value = -1, inplace=True)"
      ],
      "metadata": {
        "id": "2ZJdHdb6pRxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = dados['Potability']\n",
        "x = dados.drop(['Potability'], axis=1)"
      ],
      "metadata": {
        "id": "xzIRPIoXpuwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "q7i3bxGhp4av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size =(0.3))"
      ],
      "metadata": {
        "id": "Zldb3QSDqcDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n"
      ],
      "metadata": {
        "id": "rJN6T4oxqRoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(units=32, activation='relu', input_dim=len(x_train.columns)))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=256, activation='relu'))\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "Mgs2rwkdqVsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics='accuracy')"
      ],
      "metadata": {
        "id": "p9JmZfnrqjGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STWTzYrkqaBk",
        "outputId": "9b16e59c-9683-4c50-ef93-b2197c50cef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_50 (Dense)            (None, 32)                320       \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84,993\n",
            "Trainable params: 84,993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=120, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b773NzSRqn_F",
        "outputId": "2322197b-d575-4529-9319-89c6e5926397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 1.6471 - accuracy: 0.5316\n",
            "Epoch 2/120\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.4515 - accuracy: 0.5233\n",
            "Epoch 3/120\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.1102 - accuracy: 0.5137\n",
            "Epoch 4/120\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.9832 - accuracy: 0.5198\n",
            "Epoch 5/120\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 1.1234 - accuracy: 0.5207\n",
            "Epoch 6/120\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.8660 - accuracy: 0.5111\n",
            "Epoch 7/120\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7320 - accuracy: 0.5604\n",
            "Epoch 8/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9924 - accuracy: 0.5207\n",
            "Epoch 9/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8402 - accuracy: 0.5172\n",
            "Epoch 10/120\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7848 - accuracy: 0.5377\n",
            "Epoch 11/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8922 - accuracy: 0.5355\n",
            "Epoch 12/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7043 - accuracy: 0.5652\n",
            "Epoch 13/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7985 - accuracy: 0.5233\n",
            "Epoch 14/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7212 - accuracy: 0.5569\n",
            "Epoch 15/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7325 - accuracy: 0.5347\n",
            "Epoch 16/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7184 - accuracy: 0.5595\n",
            "Epoch 17/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7101 - accuracy: 0.5521\n",
            "Epoch 18/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7926 - accuracy: 0.5447\n",
            "Epoch 19/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7273 - accuracy: 0.5656\n",
            "Epoch 20/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7666 - accuracy: 0.5334\n",
            "Epoch 21/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.5809\n",
            "Epoch 22/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7213 - accuracy: 0.5604\n",
            "Epoch 23/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7186 - accuracy: 0.5600\n",
            "Epoch 24/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7098 - accuracy: 0.5569\n",
            "Epoch 25/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7211 - accuracy: 0.5656\n",
            "Epoch 26/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7348 - accuracy: 0.5451\n",
            "Epoch 27/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.9870 - accuracy: 0.5456\n",
            "Epoch 28/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8153 - accuracy: 0.5299\n",
            "Epoch 29/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.5512\n",
            "Epoch 30/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7282 - accuracy: 0.5626\n",
            "Epoch 31/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7470 - accuracy: 0.5360\n",
            "Epoch 32/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7597 - accuracy: 0.5512\n",
            "Epoch 33/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.5809\n",
            "Epoch 34/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.5508\n",
            "Epoch 35/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7056 - accuracy: 0.5587\n",
            "Epoch 36/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6987 - accuracy: 0.5652\n",
            "Epoch 37/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7074 - accuracy: 0.5543\n",
            "Epoch 38/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6972 - accuracy: 0.5687\n",
            "Epoch 39/120\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.7254 - accuracy: 0.5582\n",
            "Epoch 40/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7120 - accuracy: 0.5678\n",
            "Epoch 41/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6838 - accuracy: 0.5813\n",
            "Epoch 42/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.5783\n",
            "Epoch 43/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6851 - accuracy: 0.5857\n",
            "Epoch 44/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6749 - accuracy: 0.5957\n",
            "Epoch 45/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.5905\n",
            "Epoch 46/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.5879\n",
            "Epoch 47/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6795 - accuracy: 0.5866\n",
            "Epoch 48/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.5735\n",
            "Epoch 49/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.5726\n",
            "Epoch 50/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6790 - accuracy: 0.5931\n",
            "Epoch 51/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7498 - accuracy: 0.5617\n",
            "Epoch 52/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7193 - accuracy: 0.5600\n",
            "Epoch 53/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.5778\n",
            "Epoch 54/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7561 - accuracy: 0.5608\n",
            "Epoch 55/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7203 - accuracy: 0.5438\n",
            "Epoch 56/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.5883\n",
            "Epoch 57/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.6001\n",
            "Epoch 58/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.6010\n",
            "Epoch 59/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6707 - accuracy: 0.5997\n",
            "Epoch 60/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.6005\n",
            "Epoch 61/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.6010\n",
            "Epoch 62/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.6005\n",
            "Epoch 63/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6701 - accuracy: 0.6010\n",
            "Epoch 64/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.6010\n",
            "Epoch 65/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 3.1605 - accuracy: 0.5499\n",
            "Epoch 66/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7254 - accuracy: 0.5547\n",
            "Epoch 67/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6974 - accuracy: 0.5626\n",
            "Epoch 68/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6812 - accuracy: 0.5944\n",
            "Epoch 69/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6774 - accuracy: 0.5940\n",
            "Epoch 70/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6780 - accuracy: 0.5840\n",
            "Epoch 71/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.6001\n",
            "Epoch 72/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.5997\n",
            "Epoch 73/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.6001\n",
            "Epoch 74/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6762 - accuracy: 0.5949\n",
            "Epoch 75/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6738 - accuracy: 0.5988\n",
            "Epoch 76/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6734 - accuracy: 0.5883\n",
            "Epoch 77/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.6001\n",
            "Epoch 78/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6733 - accuracy: 0.6005\n",
            "Epoch 79/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.6005\n",
            "Epoch 80/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6710 - accuracy: 0.6005\n",
            "Epoch 81/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.6005\n",
            "Epoch 82/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.6005\n",
            "Epoch 83/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.6005\n",
            "Epoch 84/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.6005\n",
            "Epoch 85/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7070 - accuracy: 0.5665\n",
            "Epoch 86/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6867 - accuracy: 0.5848\n",
            "Epoch 87/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6800 - accuracy: 0.5949\n",
            "Epoch 88/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.5992\n",
            "Epoch 89/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6005\n",
            "Epoch 90/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.6010\n",
            "Epoch 91/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6710 - accuracy: 0.6010\n",
            "Epoch 92/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.6005\n",
            "Epoch 93/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.6010\n",
            "Epoch 94/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.6005\n",
            "Epoch 95/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.6010\n",
            "Epoch 96/120\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6712 - accuracy: 0.6010\n",
            "Epoch 97/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6743 - accuracy: 0.5975\n",
            "Epoch 98/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.6005\n",
            "Epoch 99/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.5914\n",
            "Epoch 100/120\n",
            "72/72 [==============================] - 0s 4ms/step - loss: 0.6743 - accuracy: 0.6010\n",
            "Epoch 101/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.5997\n",
            "Epoch 102/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.6005\n",
            "Epoch 103/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6005\n",
            "Epoch 104/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.6005\n",
            "Epoch 105/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6005\n",
            "Epoch 106/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6714 - accuracy: 0.6005\n",
            "Epoch 107/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6005\n",
            "Epoch 108/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6005\n",
            "Epoch 109/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.5944\n",
            "Epoch 110/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6005\n",
            "Epoch 111/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6005\n",
            "Epoch 112/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.6005\n",
            "Epoch 113/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.6005\n",
            "Epoch 114/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.6005\n",
            "Epoch 115/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.6005\n",
            "Epoch 116/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.5979\n",
            "Epoch 117/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.8178 - accuracy: 0.5879\n",
            "Epoch 118/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.7396 - accuracy: 0.5835\n",
            "Epoch 119/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.5997\n",
            "Epoch 120/120\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.6005\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f14351f8c90>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    }
  ]
}